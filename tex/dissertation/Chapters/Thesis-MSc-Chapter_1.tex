% #############################################################################
% This is Chapter 1
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Introduction}
\cleardoublepage
% The following line allows to ref this chapter
\label{chap:intro}
Referring Instance Segmentation is a fundamental task in computer vision that requires models to identify and segment specific object instances using natural language descriptions. When applied to aerial photographs, also referred to as Referring Remote Sensing Instance Segmentation (RRSIS)~\cite{yuan2023rrsis}, this task represents a major challenge due to the intricate characteristics of aerial imagery, including varying scales and resolutions of top-down perspectives, geographic complexities, extreme object density variations, and unique spatial relationships not present in ground-level photography.

A critical component for developing effective models for RRSIS is access to high-quality datasets containing aerial photographs, precise segmentation masks, and natural referring expressions. To address this need, we introduce Aerial-D, the largest referring segmentation dataset for aerial imagery to date, comprising 1,522,523 expressions across 37,288 aerial image patches, compared with prior RRSIS benchmarks~\cite{yuan2023rrsis,liu2024rotated,yang2024large}. As detailed in the dataset statistics presented in Chapter 4, this corpus spans rural and urban scenes and objects, land-cover regions, groups of multiple objects, and entire categories while retaining unrestricted, richly worded referring expressions tailored to each target. The primary focus of Aerial-D is not only to provide exceptional training data quality but also to establish the most challenging benchmark for RRSIS to date, which will hopefully prompt research into novel RRSIS model architectures that can surpass current performance limitations.

% #############################################################################
\section{Contributions}

The key contributions of this thesis include:

\textbf{(1) Comprehensive Dataset Generation Tools}: We introduce a comprehensive set of tools that enable the production of complex referring expression datasets from instance segmentation datasets, including a rule-based pipeline, novel LLM enhancement and distillation methods, and historic image data augmentation using proposed filters.

\textbf{(2) Aerial-D Dataset}: Using these tools, we construct Aerial-D, a massive dataset comprising over 1.5 million expressions across 37,288 aerial image patches, representing the largest referring segmentation dataset for aerial imagery to date.

\textbf{(3) Unified Multi-Dataset Model}: We present a unified model trained on Aerial-D alongside four additional datasets, applying our tools including historic transformations across all training data. This model demonstrates capabilities for referring instance segmentation, referring group segmentation, class-based segmentation, land cover segmentation, and robust handling of historic imagery including black and white, grainy, or sepia photographs.
% #############################################################################
\section{Document Structure}

This thesis is organized into six chapters and one appendix, each addressing distinct aspects of the methodology and evaluation:

\textbf{Chapter 2: Fundamental Concepts} establishes the theoretical foundation by introducing neural networks and deep learning principles, transformer architectures, computer vision fundamentals for image segmentation, and vision-language models. This chapter covers essential background on CLIP models, large language models, and the intersection of computer vision and natural language processing that enables referring segmentation.

\textbf{Chapter 3: Related Work} provides a comprehensive review of existing research in aerial image segmentation datasets, ranging from traditional semantic and instance segmentation datasets to specialized referring segmentation benchmarks. The chapter examines vision backbones for segmentation tasks, state-of-the-art referring segmentation models, and the emerging application of large language models to computer vision problems.

\textbf{Chapter 4: Aerial-D Dataset Construction} presents the systematic methodology for constructing the Aerial-D dataset. The chapter details the source datasets (iSAID~\cite{zamir2019isaid} and LoveDA~\cite{wang2021loveda}), the rule-based expression generation pipeline that transforms instance and semantic masks into referring expressions, LLM-based enhancement techniques using Gemma3, model distillation approaches, and comprehensive dataset statistics demonstrating the scale and diversity of the final resource.

\textbf{Chapter 5: Experiments} describes the experimental evaluation of the proposed approach using the RSRefSeg model architecture. The chapter covers the model implementation details, experimental setup across multiple benchmarks, comprehensive results on Aerial-D and comparison datasets including RRSIS-D, NWPU-Refer, RefSegRS, and Urban1960SatSeg, and ablation studies analyzing the contribution of different dataset enhancement components.

\textbf{Chapter 6: Conclusion and Future Work} synthesizes the key findings and contributions of this research while identifying promising directions for future investigation. The chapter summarizes the effectiveness of the automated dataset generation approach, discusses the implications for aerial image analysis, and outlines potential extensions to other remote sensing applications.

\textbf{Appendix A: LLM Enhancement Prompt} contains the complete system and user prompts employed during the Gemma3-based enhancement phase of dataset construction, providing full transparency and reproducibility for the LLM annotation process.