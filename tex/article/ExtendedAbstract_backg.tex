%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%     File: ExtendedAbstract_backg.tex                               %
%     Tex Master: ExtendedAbstract.tex                               %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Related Work}
\label{sec:related}

This section examines the foundational datasets and architectural innovations that have shaped aerial image understanding, focusing on instance segmentation, land-cover analysis, referring segmentation, historical imagery, and specialized model architectures for remote sensing applications.

\subsection{Foundational Datasets}

\subsubsection{Instance and Semantic Segmentation}

The iSAID dataset~\cite{zamir2019isaid} established the foundation for instance segmentation in aerial imagery by providing 655,451 object instances across 15 categories in 2,806 high-resolution images. Building upon the DOTA dataset, iSAID addressed the unique challenges of aerial imagery including high object density, large scale variations, and arbitrary orientations. The dataset demonstrated that existing computer vision methods require specialized adaptation for aerial domains, as off-the-shelf approaches achieved suboptimal performance.

Complementing instance-level analysis, the LoveDA dataset~\cite{wang2021loveda} focused on land-cover semantic segmentation across urban and rural environments. Covering 536.15 km² with 0.3m resolution imagery, LoveDA enables domain adaptation research by addressing style differences between geographical environments, with urban scenes dominated by artificial objects and rural scenes containing natural elements.

\subsubsection{Referring Segmentation Evolution}

The transition from traditional segmentation to language-guided approaches began with RefSegRS~\cite{yuan2023rrsis}, which introduced the first referring remote sensing image segmentation dataset with 4,420 image-language-label triplets, establishing the RRSIS task and addressing challenges of small and scattered objects in remote sensing imagery.

RRSIS-D~\cite{liu2024rotated} represents the largest referring remote sensing image segmentation dataset with 17,402 image-caption-mask triplets, three times larger than its predecessors. The dataset utilized semi-automated annotation through the Segment Anything Model (SAM) for efficient dataset creation while maintaining annotation quality. RRSIS-D addresses unique challenges in aerial imagery including vast spatial scales and diverse object orientations across 20 different object categories and seven attribute dimensions, providing comprehensive evaluation capabilities for referring segmentation methods.

The NWPU-Refer dataset~\cite{yang2024large} further expanded scale with 15,003 high-resolution images containing 49,745 annotated targets across 30+ countries. This dataset emphasizes purely manual annotation processes for enhanced quality and supports single-object, multi-object, and non-object segmentation scenarios across 32 object categories.

\subsubsection{Historical Imagery Applications}

The Urban1960SatSeg dataset~\cite{hao2025urban1960satseg} addresses the critical gap in historical aerial imagery analysis by providing the first professionally annotated semantic segmentation dataset using mid-20th century declassified satellite imagery. Covering 1,240 km² of Xi'an, China, this dataset enables quantitative analysis of urban development patterns from the 1960s through novel unsupervised segmentation frameworks designed for grayscale, distorted historical imagery.

\subsection{Architectures for RRSIS}

Specialized architectures for referring remote sensing image segmentation have evolved to address the unique complexities of aerial imagery. The foundational RefSegRS work established basic approaches for combining language understanding with aerial image segmentation, while subsequent developments introduced more sophisticated solutions for overhead imagery challenges.

The Rotated Multi-Scale Interaction Network (RMSIN)~\cite{liu2024rotated} represents a significant architectural advancement specifically designed for remote sensing image complexities. RMSIN addresses the unique challenges in aerial imagery through three key technical modules: the Intra-scale Interaction Module (IIM) for fine-grained detail extraction, the Cross-scale Interaction Module (CIM) for comprehensive feature fusion across different scales, and Adaptive Rotated Convolution (ARC) for handling rotational variations common in aerial scenes. RMSIN achieved state-of-the-art performance with 3.64\% and 3.16\% mIoU improvements over the closest competitor LAVT, demonstrating the effectiveness of specialized architectural design for aerial imagery.

The RSRefSeg architecture~\cite{chen2025rsrefseg} pioneered the integration of foundation models for remote sensing by effectively combining CLIP and SAM. This 1.2 billion parameter model introduced the AttnPrompter bridge mechanism to convert textual semantic features into SAM-compatible prompts, achieving strong performance (cIoU: 77.04, gIoU: 64.65) through parameter-efficient LoRA fine-tuning.

The MRSNet framework~\cite{yang2024large} further advances multi-scale processing through specialized Intra-scale Feature Interaction Modules (IFIM) and Hierarchical Feature Interaction Modules (HFIM), contributing to the continued evolution of architectures tailored for aerial imagery understanding.

