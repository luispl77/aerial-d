% #############################################################################
% This is Chapter 3
% !TEX root = ../main.tex
% #############################################################################
% Change the Name of the Chapter i the following line
\fancychapter{Related Work}
\cleardoublepage
% The following line allows to ref this chapter
\label{chap:architecture}

This chapter reviews existing work in aerial image segmentation datasets, referring segmentation models, and related approaches.

% #############################################################################
\section{Aerial Image Segmentation Datasets}

Overview of datasets used for aerial imagery analysis and referring segmentation tasks.

[Reference to iSAID dataset] \cite{placeholder_isaid}

[Reference to LoveDA dataset] \cite{placeholder_loveda}

[Reference to Potsdam and Vaihingen semantic segmentation datasets] \cite{placeholder_potsdam} \cite{placeholder_vaihingen}

[Reference to RefSegRS referring segmentation dataset] \cite{placeholder_refsegrs}

[Reference to RRSIS-D dataset] \cite{placeholder_rrsis–¥}

[Reference to NWPU-Refer dataset] \cite{placeholder_nwpu}

[Reference to RISBench benchmark] \cite{placeholder_risbench}

% #############################################################################
\section{Vision Backbones for Image Segmentation}

Foundational vision models used as backbones for segmentation tasks.

[Reference to CLIP vision-language model] \cite{placeholder_clip}

[Reference to SigLIP improved vision-language training] \cite{placeholder_siglip}

[Reference to SAM segment anything model] \cite{placeholder_sam}

% #############################################################################
\section{Referring Segmentation Models}

Previous approaches to language-guided segmentation in natural and aerial images.

[Reference to LAVT model] \cite{placeholder_lavt}

[Reference to RMSIN model] \cite{placeholder_rmsin}

[Reference to FIANet model] \cite{placeholder_fianet}

[Reference to RSRefSeg model] \cite{placeholder_rsrefseg}

% #############################################################################
\section{Large Language Models for Vision}

Applications of LLMs to vision tasks and multimodal understanding.

[Reference to GPT architecture and autoregressive generation] \cite{placeholder_gpt}

[Reference to multimodal capabilities in vision-language models] \cite{placeholder_multimodal}

[Reference to Gemma 3 open source models with SigLIP vision encoder] \cite{placeholder_gemma3}

[Reference to proprietary API models: O3] \cite{placeholder_o3}

[Reference to proprietary API models: GPT-5] \cite{placeholder_gpt5}

[Reference to proprietary API models: Gemini 2.5] \cite{placeholder_gemini25}

% #############################################################################
\section{Overview}

[Synthesis of all related work - gaps identified and how this work addresses them] \cite{placeholder_synthesis}